# 神经网络优化算法

本节将会具体介绍如何通过方向传播算法（backpropagation）和梯度下降算法（gradient decent）调整神经网络中参数的取值。

梯度下降算法主要用于**优化单个参数的取值**，而反向传播算法给出了一个高效的方式在**所有参数上**使用梯度下降算法，从而使神经网络模型在训练数据上的损失函数尽可能小。